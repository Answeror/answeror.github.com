<!DOCTYPE html>
<html lang=en>
  <head>
    <meta charset=UTF-8>
    <meta http-equiv=X-UA-Compatible content='IE=edge'>
    <meta name=viewport content='width=device-width, initial-scale=1'>
    <title>Cosmo Du</title>
    <link rel=stylesheet href='static/bootstrap/css/bootstrap.min.css'>
    <style>
.blog {
  padding: 42px 0 42px 0;
}
    </style>
  </head>
  <body class=blog>
    <div class=container>
      <div class=row>
        <div class='col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1'>
          <article class=art>
            
<section class=body>
<style>
#card {
  margin-top: 42px;
  margin-bottom: 42px;
}
#desc {
  background-color: inherit;
  border: none;
  color: inherit;
  padding-top: 0;
}
#title {
  text-align: left;
  margin-top: 1em;
}
.me {
  margin-bottom: 20px;
}
.pubd {
  margin-top: 10px;
  display: none;
}
.pub {
  margin-top: 20px;
}
</style>

<h1 id=title>Cosmo Du <small><small>// Legal name: Yu Du, 杜宇</small></small></h1>

<div id=card class=row>
  <div class='col-md-4 col-xs-12'>
      <img class='me img-responsive img-rounded' src='static/me.jpg'>
  </div>
  <pre id=desc class='col-md-8 col-xs-12'>
Ph.D. candidate of State Key Lab of CAD&CG
College of Computer Science, Zhejiang University
Expected to graduate on <strong>March, 2017</strong>

    Contact: answeror [att] gmail [dot] com 
  Interests: Weakly supervised learning using
             domain knowledge
Ph.D. topic: Perceptual user interface & deep learning,
             with an emphasis on
             (1) vision-based human pose estimation and
             (2) EMG-based gesture recognition.

             [<a href='static/cv-yu-du-en.pdf' target=_blank>Résumé</a>][<a href='https://github.com/answeror/' target=_blank>Github</a>][<a href='https://scholar.google.com/citations?view_op=list_works&hl=en&user=em576AIAAAAJ&gmla=AJsN-F7uIyjxpdUeIEcRKY0_4nXfdzr0vJzcmWMDYkAZ6VE9WAHN7DJHPNl_Gs6njT8CFp_QfLKcUsF0M_2KTGwbRYJDx_fu67r4Gx0f7xPnepO7SaNGfQE' target=_blank>Google Scholar</a>]
  </pre>
</div>

<hr>
<h3>Publications</h3>
<div class=row>
  <div class='pub col-md-12'>
    [<a href='http://www.mdpi.com/1424-8220/17/3/458/pdf' target=_blank>PDF</a>][<a href='https://github.com/Answeror/adamyo' target=_blank>CODE</a>][<a href='http://zju-capg.org/myo/data' target=_blank>DATA</a>] <strong>Surface EMG-based Inter-session Gesture Recognition Enhanced by Deep Domain Adaptation</strong>
    <div>
      <strong>Yu Du</strong>, Wenguang Jin, Wentao Wei, Yu Hu and Weidong Geng
    </div>
    <div>
      <strong>Sensors</strong>, 2017
    </div>
    <div class='pubd'>
      <small>
        We present a benchmark database of HD-sEMG recordings of hand gestures performed by 23 participants, based on an 8×16 electrode array,
        and propose a deep-learning-based domain adaptation framework to enhance sEMG-based inter-session gesture recognition.
      </small>
    </div>
  </div>

  <div class='pub col-md-12'>
    [<a href='http://www.nature.com/articles/srep36571.pdf' target=_blank>PDF</a>][<a href='https://github.com/Answeror/srep' target=_blank>CODE</a>] <strong>Gesture Recognition by Instantaneous Surface EMG Images</strong>
    <div>
      Weidong Geng, <strong>Yu Du</strong>, Wenguang Jin, Wentao Wei, Yu Hu and Jiajun Li
    </div>
    <div>
      <strong>Scientific Reports</strong>, 2016
    </div>
    <div class='pubd'>
      <small>
        We present that the patterns inside the instantaneous values of high-density sEMG enables gesture recognition to be performed merely with sEMG signals at a specific instant.
      </small>
    </div>
  </div>

  <div class='pub col-md-12'>
    [<a href='http://zju-capg.org/heightmap/code-and-model.zip' target=_blank>CODE</a>] <strong>Marker-less 3D Human Motion Capture with Monocular Image Sequence and Height-Maps</strong>
    <div>
      <strong>Yu Du</strong>, Yongkang Wong, Yonghao Liu, Feilin Han, Yilin Gui, Zhen Wang, Mohan Kankanhalli and Weidong Geng
    </div>
    <div>
      European Conference on Computer Vision (<strong>ECCV</strong>), 2016
    </div>
    <div class='pubd'>
      <small>
        We propose height-map as a type of built-in prior knowledge to detect the anatomical landmarks of a human body with a single-view calibrated camera, as well as enforce the temporal constraints on the camera and 3D poses for improved skeleton-based human pose estimation.
      </small>
    </div>
  </div>
</div>
</section>
          </article>
        </div>
      </div>
    </div>
    <script src='static/bootstrap/js/bootstrap.min.js'></script>
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-10313309-4', 'auto');
ga('send', 'pageview');
    </script>
  </body>
</html>