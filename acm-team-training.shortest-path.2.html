<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset=UTF-8>
    <meta http-equiv=X-UA-Compatible content='IE=edge'>
    <meta name=viewport content='width=device-width, initial-scale=1'>
    <title>answeror@gmail.com</title>
    <link rel=stylesheet href='static/bootstrap/css/bootstrap.min.css'>
    <link rel=stylesheet href='static/style.css'>
</head>
<body class=blog>
    <div class=container>
        <div class=row>
            <div class='col-md-8 col-md-offset-2'>
                <ul class='nav nav-pills'>
                    <li><a href='index.html' title='home'>home</a></li>
                    <li><a href='about.html' title='about'>about</a></li>
                </ul>
                <article class=art>
                    <section class=head>
    <h1 class=title>Shortest Path, Part II: Label-Correcting</h1>
    
    <h2><time class=ctime datetime='2011-05-01'>2011-05-01</time></h2>
</section>
<section class=body>
<h1>Material</h1>
<ul>
<li>{CLRS}24和25章</li>
<li>{黑书}2.5.2节</li>
<li>{OI论文}{2006}{余远铭}{最短路算法及其应用}</li>
<li>{OI论文}{2006}{冯威}{数与图的完美结合——浅析差分约束系统}</li>
<li>{ http://imlazy.ycool.com/post.1702305.html }: 对于差分约束很好的讲解.</li>
<li>{OI论文}{2009}{姜碧野}{SPFA算法的优化及应用}(这是一篇比较有争议的文章, 后面会提到)</li>
<li>{Shortest Paths and Negative Cycle Detection in Graphs with Negative Weights}{ http://goo.gl/cE7Mi }(以下简称{S}, 一篇货真价实的对于Bellman-Ford的各种变形的性能测试报告, 读完就会知道为什么SPFA为很多人所不齿)</li>
</ul>
<h1>Knowledge</h1>
<p>在{Shorest Path, Part I: Label-Setting}一文中, 我们讨论了最短路问题的建图, 及其部分算法. 其中细节在此不再累述.</p>
<h2>Label correcting</h2>
<p>最短路算法(仅指{CLRS}上提到的这几个)的本质是构造松弛序列. 其中, 标号设定(定标)算法的松弛序列是由最短路径图(去掉叶子)上的一个拓扑顺序构造的(在Dijkstra中, 这个拓扑顺序是贪心的到的); 而标号修正算法是一个迭代过程, 每次松弛都是对标号的一次修正, 其中对于满足路径松弛性质({CLRS}P361)的松弛序列, 可以证明算法在多项式时间内收敛.</p>
<p>标号修正算法中的典型是Bellman-Ford, 所谓的SPFA只不过是Bellman-Ford众多实现方法中的一种而已, 我们通常所说的Bellman-Ford是最最简单的一种实现方式. 后文中有对于Bellman-Ford的一些探讨.</p>
<p>以上最短路算法的讨论都是针对单源最短路的, 当求解每对顶点的最短路时, 大多使用基于DP思想的Floyd算法({CLRS}25.2节)或矩阵乘法({CLRS}25.1节). 这两个方法本质上仍然是标号修正算法, 只不过其收敛性是由DP过程保证的, 而不是由路径松弛性质保证的.</p>
<h2>Toporder again</h2>
<p>为什么我老是纠结于这种理论的东西呢? 因为它对于理解最短路算法和DP都至关重要. 具体说来, 拓扑顺序是Dijkstra的核心, 是DP的前提.</p>
<h3>DP and Shortest Path Problem</h3>
<p>在{Numerical Recipes}{3ed}的10.13节中对DP和最短路的关系有一个简明的阐述. 一句话: <b>DP就是在问题的状态图上执行最短路算法</b>.</p>
<p>因为能够DP的问题的状态图必须是DAG, 所以这个最短路算法就是{CLRS}24.2节的<code>DAG-SHORTEST-PATHS</code>, 即按照状态图上任意一个拓扑顺序构造松弛序列.</p>
<h3>Label correnting and Toporder</h3>
<p>Floyd和矩阵乘法都是DP算法, 所以都构造了拓扑顺序.</p>
<p>且慢, 这不是自相矛盾吗? 我之前说这两个算法也是标号修正算法. 既然有了拓扑顺序, 为什么还叫它标号修正呢? 拓扑顺序的定义不是每个顶点(作为松弛弧头)只能出现一次(在松弛序列中连续出现的合并起来)吗? 请注意, 这个拓扑顺序并不是原图上的, 也不是最短路径图上的, 这个拓扑顺序是针对问题的状态图来说的, 也就是说原图中一个顶点的n种状态就对应了新图中的n个顶点. 而标号修正是针对原图来说的, 虽然算法在状态图上按照拓扑序执行, 但是算法执行过程中对于原图的同一个顶点的不同状态的标号进行过赋值, 反映到原图中, 就是对于这个点的标号的多次更新了.</p>
<h2>Bellman-Ford only</h2>
<p><strong>警告: 本节内容大多是我个人的理解, 正确性有待考究, 请谨慎阅读.</strong></p>
<blockquote>
<p>世上本没有SPFA, 说的人多了, 也就成了SPFA. from: { http://goo.gl/XYbfN }</p>
</blockquote>
<p>很多人都以为Bellman-Ford就是{CLRS}24.1节的那短短8行伪代码, 或者是"没有relax就break"的优化版. 其实不然, 那仅仅是Bellman-Ford的一种最最简单的实现. 我认为凡是构造了满足路径松弛性质的松弛序列的单源最短路算法都是Bellman-Ford, 更准确地说, 是Bellman-Ford-Moorei(BFM).</p>
<p>下面的讨论都是基于{S}一文的.</p>
<h3>N-Pass Algorithm</h3>
<p>为简化讨论, 我对{S}一文中的"N-Pass Algorithm"做了一点修改, 省略了负环判断部分.</p>
<div class="codehilite"><pre><span class="n">N</span><span class="o">-</span><span class="n">PASS</span><span class="o">-</span><span class="n">ALGORITHM</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">init</span> <span class="n">array</span> <span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">other</span> <span class="o">=</span> <span class="n">inf</span>
    <span class="n">init</span> <span class="n">set</span> <span class="n">A</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">}</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">init</span> <span class="n">set</span> <span class="n">B</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">u</span> <span class="n">in</span> <span class="n">A</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">for</span> <span class="n">each</span> <span class="n">arc</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">d</span><span class="p">[</span><span class="n">v</span><span class="p">])</span> <span class="p">{</span>
                    <span class="n">d</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">v</span> <span class="n">not</span> <span class="n">in</span> <span class="n">A</span> <span class="k">union</span> <span class="n">B</span><span class="p">)</span> <span class="p">{</span>
                        <span class="n">push</span> <span class="n">v</span> <span class="n">into</span> <span class="n">B</span>
                    <span class="p">}</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">B</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>


<p>其中集合A和B可以是任意数据结构, set, stack, queue, deque...</p>
<p>算法的正确性有两种证明方法:</p>
<ol>
<li>用路径松弛性质证明.</li>
<li>用数学归纳法证明最外层循环到第i轮时包含i条边的最短路已经全部求出.</li>
</ol>
<p>传统的BFM算法中, 集合A, B都是队列. 稍微观察便知, 当使用队列时, A和B是可以合并的, 此时便有了所谓的SPFA.</p>
<p>如果让A恒等于V, B也就没有存在的意义了, 于是就两个内循环就可以合并成一个对于弧的遍历, 这便是{CLRS}上的Bellman-Ford.</p>
<h3>Negative cycle detection</h3>
<p>读到这里, 应该很容易想到怎样在<code>N-PASS-ALGORITHM</code>加入负环检测了, 最直接的莫过于把{CLRS}中的负环检测循环接在后面.这与SPFA中的"入队n次"判断是等价的, 因为当v第n次入队的时候<code>N-PASS-ALGORITHM</code>的最外层循环已经结束了.</p>
<p>更好的负环检测方法? 当然有. 但是我不想说, 原因有2:</p>
<ol>
<li>代码过长.</li>
<li>我实现的版本用在ACM题上都很慢.</li>
</ol>
<p>有兴趣的同学可以去看看, 叫做"subtree disassembly", 由Tarjan在1981年提出的.</p>
<h3>Some misunderstanding</h3>
<p>我单独拿出一节来讲BFM, 并不是为了批判SPFA, 而是为了纠正SPFA在使用过程中的一些误区. 毕竟, 名字仅仅是个代号而已.</p>
<h4>Stack based SPFA</h4>
<p>如果你分成A, B两个栈, 没问题, just do it as you wish. 但是你会发现它在某些ACM题中失去了"单栈SPFA"神奇的速度.</p>
<p>如果你坚持用一个栈, 那么有两个问题: 首先, 它的时间上界是指数级的; 其次, 你不能用"入栈n次"来判负环. 关于第一个问题, 在{ http://goo.gl/agrc6 }中有详细的解释. 而第二个问题几乎无需解释, 因为你无法证明其正确性.</p>
<h4>DFS based SPFA</h4>
<p>源自{SPFA算法的优化及应用}一文.</p>
<p>他的负环判断方法倒是没错, 不过上界跟上面的一样, 是指数级的.</p>
<p>好处是实现简单, 如果真遇到坑爹的卡数据的题目, 可以尝试这个方法.</p>
<h4>Break before n times</h4>
<p>ICPC界的这个说法大概是在10年的哈尔滨区域赛之后流行起来的, 题目是{HDU}{3666}{THE MATRIX PROBLEM}.</p>
<p>当然, 这并不是SPFA的专利, 不论是哪种BFM的实现, 在最外层循环不到n次就算负环出来效果都跟SPFA入队不到n次就算负环是一个意思.</p>
<p>但是要注意的是这仅仅是一个概率性的东西, 如果你是用单栈实现的SPFA, 正确的概率就更小了.</p>
<p>另外, 用3.3.2节的方法也能过HDU上的这题.</p>
<h2>Difference constraints</h2>
<p>{CLRS}的24.4节和{ http://imlazy.ycool.com/post.1702305.html }中已经讲得很清楚了, 这里做一点补充.</p>
<h3>Log</h3>
<p>当路长累积关系不是加法而是乘法的时候取对数.</p>
<h3>Virtual vertex</h3>
<p>虚点的引入是为了解决原图不连通的问题的, 如果原图是连通的, 或者初始A=V, 则没有必要加虚点. 事实上, 我做过的所有差分约束题目都没有加虚点.</p>
<h3>Init value of d</h3>
<p>关于d数组的初值应该是多少曾困扰我很久. 其实很简单, 看了下面一节就清楚了. 在这里单独提出来是为了引起大家的重视.</p>
<h3>Max and min</h3>
<p>差分约束题目的提问方式大约有3种:</p>
<ol>
<li>问约束是否能满足.</li>
<li>固定了一个变量, 问另外的某个变量的最大/最小值是多少.</li>
<li>问两个变量的差的绝对值最大/最小值是多少. (例如{ECUST}{238}{The Ninja Way})</li>
</ol>
<p>还有一种是问两个变量的差的最大/最小值是多少, 这跟2是一个意思.</p>
<p>对于1, 直接判负环即可. 下面我们讨论2和3.</p>
<p>首先回忆{CLRS}P361的"上界性质", 意思就是说基于松弛的方法d的值一旦达到最短路径长度就不会再减小. 所以执行BFM之后d中的值都会尽可能的大. 所以对于问题2, 假设被固定的变量为s. 若求最大值, 则令d[s]=0, other=inf; 若求最小值, d[s]=0, other=-inf, 然后BFM求最长路即可.</p>
<p>对于问题3, 事情就变得麻烦了. 假设两个变量是u和v, 求最大值. 如果最终u&lt;v, 则应该用2中求最大值的方法, 固定u, 或者用2中求最小值的方法, 固定v; 如果最终v&lt;u, 则跟前面一种情况相反, 应该(最大值, 固定v), 或者(最小值, 固定u).</p>
<p>最简单的方法就是按照2中求最大值的方法, 分别固定u和v, 做两次BFM, 则|dis(u,v)|的最大和最小值都出来了.</p>
<p>有人要问, 万一u和v不连通怎么办? 不连通的话这两个变量就没关系了, 哪来什么最大最小...</p>
<p>现在回到d数组的初值上来. 我们考虑d的初值的意义. 在有虚点时, 我们通常另虚点v的d为x, v到点u连权为y的弧, 表示约束u-v&lt;=y(注意这里u和v表示变量, 不是顶点的标号). 把v拿到右边来, 根据上界性质, d[v]在之后不会减小(因为没有连往v的弧), 所以u&lt;=x+y, 即相当于给变量u又加了一个约束.</p>
<p>当有虚点时, 通常我们令除虚点意外的d为inf, 这个inf的目的仅仅是为表示一个无意义的值而已, 好让针对该点的第一次松弛能够生效. 当虚点作为弧头扩展后, 对于任意一个非虚点u, d[u]=x+y. 所以如果不要虚点, 初始令A=V, d[u]=x+y, 则跟有虚点时的效果是一样的. 这时d的意义就是约束u&lt;=x+y.</p>
<p>所以上面针对问题2, 求最大值时other=inf, 而求最小值时other=-inf, 此时inf就不仅仅表示一个无意义的值了, 它表示的是一个实实在在的约束, 目的是施加约束使被固定的点和其余点的距离尽可能的大.</p>
<p>如果针对问题1, 则d设任意值都是可以的, 因为差分约束的结果可以集体偏移一个常数, 所以这些通过d初值施加的约束总是可以被满足.</p>
<h1>Problem</h1>
<p>限于时间关系, 没来得及整理例题, 除了上面提到的两题差分约束(包含了取对数, 负环检测和最值三个知识点)以外, 还有矩阵乘法求最短路的经典题目{PKU}{3613}{Cow Relays}, 比好玩的{ZJU}{3232}{It's not Floyd Algorithm}, 后面这题真的不是Floyd, 题解参见{ http://www.answeror.com/archives/28443 }.</p>
<h1>Acknowledgement</h1>
<p>该文为华东理工大学2011年ACM培训内容之一, 作者Answeror, 转载请注明出处. 其余培训专题详见<a href="http://202.120.106.94/knowledge/group.php?action=show&amp;id=177">这里</a>.</p>
</section>
                </article>
            </div>
        </div>
    </div>
    <script src='static/bootstrap/js/bootstrap.min.js'></script>
</body>
</html>